{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Reference:\n- https://www.kaggle.com/kaushal2896/global-wheat-detection-starter-eda","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from imutils import paths\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/global-wheat-detection/train.csv')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From [this description](https://www.kaggle.com/c/global-wheat-detection/data), we have - \n\n- image_id - the unique image ID\n- width, height - the width and height of the images\n- bbox - a bounding box, formatted as a Python-style list of [xmin, ymin, width, height]\n- etc.\n\nIt's important to note that not all images have bounding boxes.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# How many unique images?\nlen(train_df[\"image_id\"].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Total number of entries\ntrain_df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Total number of images in the training directory\n#len(list(paths.list_images(\"train\")))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This means that `3422 - 3373` i.e. **49 images** do not have any annotations. [This notebook](https://www.kaggle.com/kaushal2896/global-wheat-detection-starter-eda) does an excellent job at providing more insights. Be sure to check it out. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\nimport ast","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separating out the coordinates\nxmin, ymin, width, height = [], [], [], []\n\nfor i in tqdm(train_df[\"bbox\"]):\n    cooridinates_list = ast.literal_eval(i)\n    xmin.append(cooridinates_list[0])\n    ymin.append(cooridinates_list[1])\n    width.append(cooridinates_list[2])\n    height.append(cooridinates_list[3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(xmin), len(ymin), len(width), len(height)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"xmin\"] = xmin\ntrain_df[\"ymin\"] = ymin\ntrain_df[\"width\"] = width\ntrain_df[\"height\"] = height\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing some samples from the training set\n\nsample_indices = np.random.choice(np.unique(train_df[\"image_id\"].tolist()), 8)\n\nfig, ax = plt.subplots(nrows=2, ncols=4, figsize=(20, 10))\ncount=0\n\nfor row in ax:\n    for col in row:\n        img = plt.imread(\"train/\" + sample_indices[count] + \".jpg\")\n        col.grid(False)\n        col.set_xticks([])\n        col.set_yticks([])\n        col.imshow(img)\n        count += 1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize the images with bounding boxes\nimport matplotlib.patches as patches\n\ndef get_bbox(image_id, df, col, color='white'):\n    bboxes = df[df['image_id'] == image_id]\n    \n    for i in range(len(bboxes)):\n        # Create a Rectangle patch\n        rect = patches.Rectangle(\n            (bboxes['xmin'].iloc[i], bboxes['ymin'].iloc[i]),\n            bboxes['width'].iloc[i], \n            bboxes['height'].iloc[i], \n            linewidth=2, \n            edgecolor=color, \n            facecolor='none')\n\n        # Add the patch to the Axes\n        col.add_patch(rect)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(20, 10))\ncount=0\nfor row in ax:\n    for col in row:\n        img = plt.imread(\"train/\" + sample_indices[count] + \".jpg\")\n        col.grid(False)\n        col.set_xticks([])\n        col.set_yticks([])\n        get_bbox(sample_indices[count], train_df, col, color='red')\n        col.imshow(img)\n        count += 1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Images without bounding box\nimages_w_bbox = train_df[\"image_id\"].unique()\nimages_w_bbox = [\"train/\" + image_id + \".jpg\" for image_id in images_w_bbox]\n\nall_images = list(paths.list_images(\"train\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_w_bbox[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_images[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_wo_bbox = list(set(all_images) - set(images_w_bbox))\nimages_wo_bbox[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing some images without any wheat heads\n\nfig, ax = plt.subplots(nrows=2, ncols=2, figsize=(20, 10))\ncount=0\n\nfor row in ax:\n    for col in row:\n        img = plt.imread(images_wo_bbox[count])\n        col.grid(False)\n        col.set_xticks([])\n        col.set_yticks([])\n        col.imshow(img)\n        count += 1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Serialize `train_df` to a .csv file\ntrain_df.to_csv(\"train_df.csv\", index=False)\n!head -5 train_df.csv","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}